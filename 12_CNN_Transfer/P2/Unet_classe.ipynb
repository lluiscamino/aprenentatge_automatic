{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de Unet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Per treballar amb COCO necessitam instal·lar aquesta llibreria.\n",
        "# Cada cop que iniciam l'entorn s'ha d'executar\n",
        "\n",
        "!pip install pycocotools"
      ],
      "metadata": {
        "id": "_qIxrusyeNr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UNET\n",
        "\n",
        "## Cárrega de dades\n",
        "\n",
        "En primer lloc hem de carregar les dades necessàries. Com hem comentat a l'enunciat farem feina amb la versió 2014 de [COCO](https://cocodataset.org#home)"
      ],
      "metadata": {
        "id": "2AOQ0tlSP-pg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from pycocotools.coco import COCO\n",
        "import pycocotools.mask as maskUtils"
      ],
      "metadata": {
        "id": "t-z2WTjCaKHt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al vostre google drive heu de tenir una carpeta anomenada `unet_aa`.  En aquesta\n",
        "carpeta hi heu de **descomprimir** la informació del dataset [enllaç](http://images.cocodataset.org/annotations/annotations_trainval2014.zip) . Si l'enllaç no funciona podeu anar a la secció de descarregues i cercar _2014 Train/Val annotations [241MB]_.\n",
        "\n",
        "També heu de crear una carpeta anomenada _license_.\n",
        "\n",
        "El següent codi, permet connectar el _notebook_ de colab amb aquesta carpeta. En executar-ho us demanarà permís explicit per accedir-hi mitjançant un pop-up."
      ],
      "metadata": {
        "id": "9ppeXC9vgTJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/My Drive/unet_aa"
      ],
      "metadata": {
        "id": "KScb1q-PGBWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Les categories que podem emprar del COCO són:** \n",
        "person, bicycle, car, motorcycle, airplane, bus, train, truck, boat, traffic light, fire hydrant stop sign, parking meter, bench, bird, cat, dog, horse, sheep, cow, elephant, bear, zebra, giraffe, backpack, umbrella, handbag, tie, suitcase, frisbee, skis, snowboard, sports, ball, kite, baseball, bat, baseball, glove, skateboard, surfboard, tennis racket, bottle, wine, glass cup, fork, knife, spoon, bowl, banana, apple, sandwich, orange, broccoli, carrot, hot dog, pizza, donut, cake, chair, couch, potted, plant, bed, dining table, toilet, tv, laptop, mouse, remote, keyboard, cell phone, microwave, oven, toaster, sink, refrigerator, book, clock, vase, scissors, teddy bear, hair drier, toothbrush.\n",
        "\n",
        "A continuació teniu un **generador** que ens permet tenir un conjunt d'entrenament i un conjunt de test. Aquests generadors tenen tres paràmetres: la categoría, la mida del _batch_ i un _booleà_ que ens indica si es el generador del conjunt d'entrenament o de test. "
      ],
      "metadata": {
        "id": "sj9tnXoSzLBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyGeneration(tf.keras.utils.Sequence):\n",
        "  \n",
        "  def __init__(self, category, batch_size, train=True):\n",
        "\n",
        "    dataDir = ''\n",
        "    dataType = 'val2014'\n",
        "    annFile = '{}annotations/instances_{}.json'.format(dataDir,dataType)\n",
        "\n",
        "    self.coco = COCO(annFile)\n",
        "    \n",
        "    self.batch_size = batch_size\n",
        "    self.cat = category\n",
        "    self.catIds = self.coco.getCatIds(catNms=['dog']);\n",
        "    self.imgIds = self.coco.getImgIds(catIds=self.catIds);\n",
        "    \n",
        "    if train:\n",
        "      self.imgIds = self.imgIds[:int(len(self.imgIds)*0.75)]\n",
        "    else: \n",
        "      self.imgIds = self.imgIds[int(len(self.imgIds)*0.75):]\n",
        "  \n",
        "  def __len__(self):  \n",
        "    return math.ceil(len(self.imgIds) / self.batch_size)\n",
        "    \n",
        "  def __getitem__(self, idx):\n",
        "    \n",
        "    batch_x = self.coco.loadImgs(self.imgIds[idx * self.batch_size:(idx + 1) * self.batch_size])\n",
        "    \n",
        "    self.annIds = self.coco.getAnnIds(imgIds=self.imgIds[idx * self.batch_size:(idx + 1) * self.batch_size],\n",
        "                                 catIds=self.catIds, iscrowd=False)\n",
        "    \n",
        "    pre_batch_y = []\n",
        "\n",
        "    for img_id in self.imgIds[idx * self.batch_size:(idx + 1) * self.batch_size]:\n",
        "\n",
        "      annIds      = self.coco.getAnnIds(imgIds=img_id, catIds=self.catIds, iscrowd=False)\n",
        "      annotations = self.coco.loadAnns(annIds)\n",
        "      mask        = self.coco.annToMask(annotations[0])\n",
        "      \n",
        "      for ann in annotations[1:]:\n",
        "        mask += self.coco.annToMask(ann)\n",
        "      mask = resize(mask, (256, 256, 1))\n",
        "      mask[mask>0] = 1\n",
        "\n",
        "      pre_batch_y.append(mask)\n",
        "\n",
        "\n",
        "    return (np.array([resize(imread(file_name['coco_url']), (256, 256)) for file_name in batch_x]), \n",
        "            np.array([mask for mask in pre_batch_y]))"
      ],
      "metadata": {
        "id": "7eNiuG8hJIFE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalment només ens queda crear els dos generadors:"
      ],
      "metadata": {
        "id": "GycSH9iThyeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_train = MyGeneration('dog', 10)\n",
        "gen_test = MyGeneration('dog', 10, False)\n"
      ],
      "metadata": {
        "id": "-J6HgBoCNoMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importar les llibreries"
      ],
      "metadata": {
        "id": "o1Aqx-YyQlNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras import backend as keras"
      ],
      "metadata": {
        "id": "bGKdRiv9QkIv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definició del model\n"
      ],
      "metadata": {
        "id": "Ktbp1Q__Qoq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unet(input_size = (256, 256, 3), output_channels = 1):\n",
        "\n",
        "    dilation_rate = 1 # No modificar\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(16, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(inputs)\n",
        "    conv1 = Conv2D(16, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2), data_format='channels_last')(conv1)\n",
        "\n",
        "    conv2 = Conv2D(32, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(pool1)\n",
        "    conv2 = Conv2D(32, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2), data_format='channels_last')(conv2)\n",
        "\n",
        "    conv3 = Conv2D(64, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(pool2)\n",
        "    conv3 = Conv2D(64, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(conv3) \n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2), data_format='channels_last')(conv3)\n",
        "\n",
        "    conv4 = Conv2D(128, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(pool3) \n",
        "    conv4 = Conv2D(128, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2), data_format='channels_last')(conv4)\n",
        "\n",
        "    conv5 = Conv2D(256, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(pool4)\n",
        "    conv5 = Conv2D(256, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(conv5)  \n",
        "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis=3)\n",
        "    \n",
        "    # TODO your code here\n",
        "    \n",
        "    return model\n"
      ],
      "metadata": {
        "id": "lJnztXpfQpAt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = unet()   \n",
        "# TODO: compilar\n",
        "\n",
        "# TODO: Entrenar\n"
      ],
      "metadata": {
        "id": "wZXFyEvON25c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaluació\n",
        "\n",
        "Teniu codi per poder visualitzar alguns resultats. Podeu modificar aquest codi al vostre gust"
      ],
      "metadata": {
        "id": "sXi_oXo0iaVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtenim el primer batch del conjunt d' avaluació\n",
        "for test in gen_test:\n",
        "  break\n",
        "\n",
        "# Realitzam la predicció\n",
        "prediccio = model.predict(test[0])\n",
        "\n",
        "# Mostram els resultats\n",
        "n_images = len(prediccio)\n",
        "\n",
        "figure = plt.figure(1, figsize=(9, 9))\n",
        "\n",
        "for i in range(n_images):\n",
        "\n",
        "  ax = plt.subplot(n_images/2, n_images//2, i + 1)\n",
        "  ax.imshow(test[0][i,:,:,:])\n",
        "  ax.set_xticks(())\n",
        "  ax.set_yticks(())\n",
        "\n",
        "figure = plt.figure(2, figsize=(9, 9))\n",
        "\n",
        "for i in range(n_images):\n",
        "\n",
        "  ax = plt.subplot(n_images/2, n_images//2, i + 1)\n",
        "  predit = prediccio[i][:,:,0]\n",
        "  predit[predit > 0.3] = 255\n",
        "  predit[predit < 255] = 0 \n",
        "  predit = predit.astype(np.uint8)\n",
        "  ax.imshow(predit) #test[1][i,:,:,0]*255)\n",
        "  ax.set_xticks(())\n",
        "  ax.set_yticks(())"
      ],
      "metadata": {
        "id": "aSxbabWr0XUI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}