{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr15yoPLDt2G"
      },
      "source": [
        "# De Scikit a Tensorflow\n",
        "\n",
        "L'objectiu d'aquest quadern és realitzar la transició entre el Multi-Layer perceptron de Scikit amb el qual vàrem treballar la setmana passada i la llibreria  TensorFlow.\n",
        "\n",
        "Avui treballarem amb xarxes on totes les neurones de cada capa es troben connectades amb les neurones de la capa següent, tal com està dissenyada la classe MLP de Scikit. \n",
        "\n",
        "Començarem usant els mateixos conjunts de dades de la darrera sessió i intentarem reproduïr resultats similars."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAQ_HE9GDR1p"
      },
      "source": [
        "# Llibreries \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_moons, make_circles, make_classification\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# TensorFlow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ei4aOWu1Dvxj"
      },
      "source": [
        "## Dades\n",
        "\n",
        "\n",
        "Generació dels conjunts de dades ja coneguts, en aquest cas tendrem conjunts de dades amb 300 mostres."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1Kq80EnDzEx"
      },
      "source": [
        "# Construïm 4 conjunts de dades per classificar:\n",
        "# En primer lloc un conjunt linealment separable on afegim renou\n",
        "X, y = make_classification(n_samples=300, n_features=2, n_redundant=0, n_informative=2, random_state=33, n_clusters_per_class=1)\n",
        "rng = np.random.RandomState(2)\n",
        "X += 2 * rng.uniform(size=X.shape)\n",
        "linearly_separable = (X, y)\n",
        "\n",
        "# En segon lloc un que segueix una distribució xor\n",
        "X_xor = np.random.randn(300, 2)\n",
        "y_xor = np.logical_xor(X_xor[:, 0] > 0,\n",
        "                       X_xor[:, 1] > 0)\n",
        "y_xor = np.where(y_xor, 1, -1)\n",
        "\n",
        "# Els afegim a una llista juntament amb els seus noms per tal de poder iterar\n",
        "# sobre ells\n",
        "datasets = [\n",
        "    (\"linear\", linearly_separable),\n",
        "    (\"moons\", make_moons(n_samples=300, noise=0.3, random_state=30)),  # Tercer dataset\n",
        "    (\"circles\", make_circles(n_samples=300, noise=0.2, factor=0.5, random_state=30)),  # Darrer dataset\n",
        "    (\"xor\", (X_xor, y_xor))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnGyanaVEUzJ"
      },
      "source": [
        "## Model\n",
        "\n",
        "Tensorflow ens permet definir l'arquitectura de les xarxes de dues maneres, en aquest cas emprarem l'entorn seqüencial. Deixarem l'entorn funcional per a futures pràctiques. \n",
        "\n",
        "Especificam les diferents capes com a part d'un objecte de la classe model.\n",
        "\n",
        "Les capes que emprarem es diuen denses `Dense` ([enllaç a la documentació](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)). \n",
        "\n",
        "Emprarem 2 paràmetres:\n",
        " - El nombre de neurones.\n",
        " - La funció d'activació.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkErmG5MEVfR"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input((2)),\n",
        "    tf.keras.layers.Dense(2, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kAuNUU8jgWl"
      },
      "source": [
        "# En alguns tutorials veureu la definició de la xarxa així:\n",
        "#model = tf.keras.Sequential()\n",
        "#model.add(tf.keras.layers.Input((2)))\n",
        "#model.add(tf.keras.layers.Dense(5, activation='relu'))\n",
        "#model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZ9pHXerQ6kk"
      },
      "source": [
        "## Compilar el model\n",
        "\n",
        "El model que em definit necessita ser compilat, en aquesta passa es defineix l'algorisme d'optimització, la funció de pèrdua i les mètriques sobre les quals volem obtenir resultats.\n",
        "\n",
        "Funcions de pèrdua:\n",
        "- Documentació [funcions de perdua](https://www.tensorflow.org/api_docs/python/tf/keras/losses?version=nightly)\n",
        "\n",
        "- Petit [tutorial](https://www.analyticsvidhya.com/blog/2021/05/guide-for-loss-function-in-tensorflow/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brBBfogaQ8Fh"
      },
      "source": [
        "model.compile(optimizer='adam', # també podria ser el descens de gradient tradicional\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-WNhuSnsx5Y"
      },
      "source": [
        "# Ens proporciona un resum de com és la nostra xarxa, fixau-vos en el nombre de\n",
        "# paràmetres\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcUbd6J6WWIt"
      },
      "source": [
        "## Entrenament\n",
        "\n",
        "El procés d'entrenament és molt similar a qualsevol altre mètode d'aprenentatge automàtic. Podem observar 2 diferències:\n",
        "\n",
        "- Hem d'explicitar el nombre d'èpoques (nombre d'iteracions de l'entrenament).\n",
        "- Podem aportar un conjunt de dades d'avaluació per tenir una estimació de la bondat del nostre model al final de cada època.\n",
        "\n",
        "Finalment veureu que la funció fit ens proporciona un diccionari (variable `history`), emprarem les dades guardades en ell per poder dibuixar els gràfics de resum l'entrenament."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeh5DPDDG6_j"
      },
      "source": [
        "# En primer lloc preparam les dades\n",
        "\n",
        "X, y = datasets[1][1]\n",
        "\n",
        "X = StandardScaler().fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=33)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CnouABWG3D2"
      },
      "source": [
        "# En segon lloc entrenam:\n",
        "# - Proporcionam les dades d'entrenament i de validació\n",
        "# - Definim el nombre d'iteracions\n",
        "# - Es pot definir el tamany del batch (batch_size)\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15)\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Dswl5kmWUA-"
      },
      "source": [
        "# (history.history.keys())\n",
        "\n",
        "# Mostram els resultats de l'entrenament de manera gràfica\n",
        "figure, ax = plt.subplots(nrows=1, ncols=2)\n",
        "\n",
        "ax[0].plot(history.history['accuracy'])\n",
        "ax[0].plot(history.history['val_accuracy'])\n",
        "\n",
        "ax[0].set_title('model accuracy')\n",
        "ax[0].set_ylabel('accuracy')\n",
        "ax[0].set_xlabel('epoch')\n",
        "ax[0].set_ylim(0,1)\n",
        "ax[0].legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "# summarize history for loss\n",
        "ax[1].plot(history.history['loss'])\n",
        "ax[1].plot(history.history['val_loss'])\n",
        "ax[1].set_ylim(0,1)\n",
        "ax[1].set_title('model loss')\n",
        "ax[1].set_ylabel('loss')\n",
        "ax[1].set_xlabel('epoch')\n",
        "ax[1].legend(['train', 'test'], loc='upper right')\n",
        "figure.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqJXZphQSDVa"
      },
      "source": [
        "## Predicció"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6WeCRvnnk8d"
      },
      "source": [
        "result = model.predict(X)\n",
        "\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}